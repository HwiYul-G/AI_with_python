{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-layer perceptron recognizes MNIST datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read MNIST datasets and split into training set and test set\n",
    "\n",
    "mnist = fetch_openml('mnist_784')\n",
    "# [0,255] 범위의 ㄱ밧을 가진 mnist의 맵을 [0,1]로 정규화한다.\n",
    "mnist.data = mnist.data/255.0\n",
    "x_train = mnist.data[:60000]; x_test = mnist.data[60000:]\n",
    "# label에 해당하는 mnist.target은 str형이므로 np.int16으로 16bit 정수형으로 변환\n",
    "# int16으로 변환해야 confusion matrix를 그릴 때 index로 사용할 수 있다.\n",
    "y_train = np.int16(mnist.target[:60000]); y_test = np.int16(mnist.target[60000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.57602850\n",
      "Iteration 2, loss = 0.21803623\n",
      "Iteration 3, loss = 0.16310442\n",
      "Iteration 4, loss = 0.13117015\n",
      "Iteration 5, loss = 0.10864824\n",
      "Iteration 6, loss = 0.09131156\n",
      "Iteration 7, loss = 0.07979289\n",
      "Iteration 8, loss = 0.06928326\n",
      "Iteration 9, loss = 0.06136687\n",
      "Iteration 10, loss = 0.05310815\n",
      "Iteration 11, loss = 0.04714037\n",
      "Iteration 12, loss = 0.04224384\n",
      "Iteration 13, loss = 0.03777294\n",
      "Iteration 14, loss = 0.03378822\n",
      "Iteration 15, loss = 0.02996263\n",
      "Iteration 16, loss = 0.02688236\n",
      "Iteration 17, loss = 0.02324713\n",
      "Iteration 18, loss = 0.02078110\n",
      "Iteration 19, loss = 0.01831288\n",
      "Iteration 20, loss = 0.01634801\n",
      "Iteration 21, loss = 0.01441233\n",
      "Iteration 22, loss = 0.01367649\n",
      "Iteration 23, loss = 0.01156694\n",
      "Iteration 24, loss = 0.01096885\n",
      "Iteration 25, loss = 0.00938109\n",
      "Iteration 26, loss = 0.00815161\n",
      "Iteration 27, loss = 0.00780883\n",
      "Iteration 28, loss = 0.00695054\n",
      "Iteration 29, loss = 0.00479899\n",
      "Iteration 30, loss = 0.00415812\n",
      "Iteration 31, loss = 0.00352253\n",
      "Iteration 32, loss = 0.00336964\n",
      "Iteration 33, loss = 0.00271009\n",
      "Iteration 34, loss = 0.00251887\n",
      "Iteration 35, loss = 0.00216635\n",
      "Iteration 36, loss = 0.00179327\n",
      "Iteration 37, loss = 0.00155520\n",
      "Iteration 38, loss = 0.00139660\n",
      "Iteration 39, loss = 0.00117280\n",
      "Iteration 40, loss = 0.00109958\n",
      "Iteration 41, loss = 0.00111828\n",
      "Iteration 42, loss = 0.00102614\n",
      "Iteration 43, loss = 0.00083558\n",
      "Iteration 44, loss = 0.00094798\n",
      "Iteration 45, loss = 0.00074546\n",
      "Iteration 46, loss = 0.00064962\n",
      "Iteration 47, loss = 0.00060876\n",
      "Iteration 48, loss = 0.00057469\n",
      "Iteration 49, loss = 0.00052185\n",
      "Iteration 50, loss = 0.00049338\n",
      "Iteration 51, loss = 0.00046373\n",
      "Iteration 52, loss = 0.00044381\n",
      "Iteration 53, loss = 0.00041401\n",
      "Iteration 54, loss = 0.00040666\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(batch_size=512, hidden_layer_sizes=(100, 100), max_iter=300,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create MLP classifier and train model\n",
    "\n",
    "# 미니 배치의 크기를 큰 값인 512로 설정했다.\n",
    "# 미니배치 크기를 크게 하면 오류 역전파 과정을 적게 수행해 학습 시간을 단축한다.\n",
    "# MPLClassifier는 가중치를 초기화할 때와 학습 도중 미니배치 구성시 난수를 사용해서 실행마다 다른 결과를 얻게 된다.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,100),\n",
    "                    learning_rate_init=0.001,\n",
    "                    batch_size=512, max_iter=300,\n",
    "                    solver='adam', verbose=True)\n",
    "mlp.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using test set\n",
    "res = mlp.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 969    0    2    0    1    2    4    1    6    1]\n",
      " [   0 1127    1    0    0    0    2    4    0    3]\n",
      " [   1    2 1007    5    4    0    2    7    5    0]\n",
      " [   0    1    8  996    0   12    1    2    6    1]\n",
      " [   2    0    1    0  965    1    6    1    6    8]\n",
      " [   1    1    1    2    0  867    5    0    5    6]\n",
      " [   2    1    2    1    1    3  934    0    2    0]\n",
      " [   3    1    4    2    2    2    0 1003    3    3]\n",
      " [   1    2    6    2    1    4    4    2  937    2]\n",
      " [   1    0    0    2    8    1    0    8    4  985]]\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "conf = np.zeros((10,10), dtype=np.int16)\n",
    "for i in range(len(res)):\n",
    "    conf[res[i]][y_test[i]] += 1\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 집합에 대한 정확률은 97.89999999999999 %입니다.\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "no_correct = 0\n",
    "for i in range(10):\n",
    "    no_correct += conf[i][i]\n",
    "accuracy = no_correct/len(res)\n",
    "print(\"테스트 집합에 대한 정확률은\", accuracy*100, \"%입니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d6becc2a03eb1d3a0003abbb7d06bd320b2f8d9ef53e81460f893735b5a2d16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
